{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 15:50:33.598372: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import data as tf_data\n",
    "from tensorflow.python.framework import ops\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.utils\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "\n",
    "keras.utils.set_random_seed(seed=42)\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/author/')\n",
    "from Utils_functions import load_and_preprocess_naca_data, SimpleBaseModel, kfold_cross_validation_MLP, PointTransformerModel, kfold_cross_validation_PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "TRAIN_SIZE = 0.70\n",
    "TEST_SIZE = 0.15\n",
    "NUM_TARGETS = 3  \n",
    "\n",
    "#C-PROP\n",
    "points_cluster, labels_cluster, train_ds_cluster, val_ds_cluster, test_ds_cluster, NUM_POINTS, NUM_FEATURES = load_and_preprocess_naca_data('data/points_prop_zenodo.npy','data/labels_zenodo.npy', \n",
    "                                                                                                                              BATCH_SIZE, TRAIN_SIZE, TEST_SIZE, augment=False, augment_factor=3, scale= True)\n",
    "\n",
    "# Schillaci et al.\n",
    "points_schilla, labels_schilla, train_ds_schilla, val_ds_schilla, test_ds_schilla, NUM_POINTS_SCHILLA, NUM_FEATURES_SCHILLA = load_and_preprocess_naca_data('data/lines_NACA_schilla_weight_complete.npy','data/labels_NACA_schilla_weight_complete.npy', \n",
    "                                                                                                                                BATCH_SIZE, TRAIN_SIZE, TEST_SIZE, augment=False, augment_factor=3, scale= True, only_p=False) # seto only p=true for CR+CR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model_schilla = SimpleBaseModel(NUM_POINTS_SCHILLA, NUM_FEATURES_SCHILLA, NUM_TARGETS)\n",
    "\n",
    "history_schilla = base_model_schilla.train(train_ds_schilla, val_ds_schilla, epochs=1000, patience=10)\n",
    "\n",
    "base_model_schilla.evaluate(test_ds_schilla)\n",
    "\n",
    "base_model_schilla.plot_training_history(history_schilla)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model_cluster = SimpleBaseModel(NUM_POINTS, NUM_FEATURES, NUM_TARGETS)\n",
    "\n",
    "history_cluster = base_model_cluster.train(train_ds_cluster, val_ds_cluster, epochs=1000, patience=10)\n",
    "\n",
    "base_model_cluster.evaluate(test_ds_cluster)\n",
    "\n",
    "base_model_cluster.plot_training_history(history_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle(\"True vs Predicted Values for Digits (Comparison of Models)\", fontsize=16)\n",
    "\n",
    "base_model_schilla.show_predictions(\n",
    "    test_ds=test_ds_schilla,\n",
    "    ax=axs[0],\n",
    "    title=\"Model Schilla Predictions\",\n",
    "    model_name=\"Model Schilla\"\n",
    ")\n",
    "\n",
    "base_model_cluster.show_predictions(\n",
    "    test_ds=test_ds_cluster,\n",
    "    ax=axs[1],\n",
    "    title=\"Model Cluster Predictions\",\n",
    "    model_name=\"Model Cluster\"\n",
    ")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95]) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mae, max_error, max_error_position = base_model_schilla.evaluate_relative_error(test_ds_schilla)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Maximum Error: {max_error:.4f}\")\n",
    "#print(f\"Position of Maximum Error: {max_error_position}\")\n",
    "\n",
    "accuracy, correct_predictions = base_model_schilla.evaluate_accuracy(test_ds_schilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate relative error\n",
    "mae, max_error, max_error_position = base_model_cluster.evaluate_relative_error(test_ds_cluster)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Maximum Error: {max_error:.4f}\")\n",
    "#print(f\"Position of Maximum Error: {max_error_position}\")\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy, correct_predictions = base_model_cluster.evaluate_accuracy(test_ds_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_cross_validation_MLP(points_schilla, labels_schilla, NUM_POINTS_SCHILLA,\n",
    "                            NUM_FEATURES_SCHILLA, NUM_TARGETS, n_splits=5, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolo dell'Accuracy: arrotondamento dei valori predetti ai valori interi\n",
    "y_true_schilla = np.concatenate([y for x, y in test_ds_schilla], axis=0)  # Label reali dal test set\n",
    "y_pred_schilla = base_model_schilla.predict(test_ds_schilla)  # Predizioni del modello sul test set\n",
    "\n",
    "# Arrotonda i valori\n",
    "y_pred_rounded_schilla= np.round(y_pred_schilla, decimals=0)  # Arrotonda le predizioni ai valori interi\n",
    "\n",
    "# Calcola l'accuracy confrontando le predizioni arrotondate con i label arrotondati\n",
    "accuracy_schilla = np.mean(np.all(y_true_schilla == y_pred_rounded_schilla, axis=1))\n",
    "accuracy_schilla_1 = np.mean(y_true_schilla[:,0] == y_pred_rounded_schilla[:,0])\n",
    "accuracy_schilla_2 = np.mean(y_true_schilla[:,1] == y_pred_rounded_schilla[:,1])\n",
    "accuracy_schilla_3 = np.mean(y_true_schilla[:,2] == y_pred_rounded_schilla[:,2])\n",
    "beccati= np.sum(np.all(y_true_schilla == y_pred_rounded_schilla, axis=1))\n",
    "print(f\"Beccati: {beccati}/{np.shape(y_true_schilla)[0]}\")\n",
    "print(f\"Test Accuracy (Classificazione): {accuracy_schilla*100:.2f}%\\n\")\n",
    "print(f\"Test Accuracy I cifra: {accuracy_schilla_1*100:.2f}%\")\n",
    "print(f\"Test Accuracy II cifra: {accuracy_schilla_2*100:.2f}%\")\n",
    "print(f\"Test Accuracy III cifra: {accuracy_schilla_3*100:.2f}%\\n\")\n",
    "\n",
    "errors = np.abs(y_true_schilla - y_pred_schilla)\n",
    "mae = np.mean(errors)\n",
    "max_error = np.max(errors)\n",
    "max_error_position = np.unravel_index(np.argmax(errors), errors.shape)\n",
    "\n",
    "mae_1 = np.mean(errors[:, 0])\n",
    "mae_2 = np.mean(errors[:, 1])\n",
    "mae_3 = np.mean(errors[:, 2])\n",
    "\n",
    "print(f\"Errore relativo Medio Perc. sulla I cifra (MAE): {mae_1:.4f}, {mae_1 / 9 * 100:.2f}%\")\n",
    "print(f\"Errore relativo Medio Perc. sulla II cifra (MAE): {mae_2:.4f}, {mae_2 / 9 * 100:.2f}%\")\n",
    "print(f\"Errore relativo Medio Perc. sulla III cifra (MAE): {mae_3:.4f}, {mae_3 / 45 * 100:.2f}%\\n\")\n",
    "\n",
    "print(f\"Errore Assoluto Medio sulla I cifra (MAE): {mae_1:.4f}, {mae_1:.3f}\")\n",
    "print(f\"Errore Assoluto Medio sulla II cifra (MAE): {mae_2:.4f}, {mae_2:.3f}\")\n",
    "print(f\"Errore Assoluto Medio sulla III cifra (MAE): {mae_3:.4f}, {mae_3:.3f}\\n\")\n",
    "\n",
    "print(f\"Errore Medio assoluto (MAE): {mae:.4f}\")\n",
    "print(f\"Errore Massimo: {max_error:.4f} in posizione {max_error_position}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "errors = np.abs(y_true_schilla[:, 0] - y_pred_schilla[:, 0])\n",
    "\n",
    "mean_error = np.mean(errors)\n",
    "\n",
    "plt.hist(errors, bins=50, alpha=0.7, label=\"Absolute Errors\")\n",
    "plt.axvline(mean_error, color='r', linestyle='dashed', linewidth=2, label=f\"Mean Error: {mean_error:.3f}\")\n",
    "\n",
    "plt.xlabel(\"Absolute Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Absolute Errors\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentuale di errori tra 0.45 e 0.5: 1.61%\n"
     ]
    }
   ],
   "source": [
    "errors = np.abs(y_true_schilla[:,2] - y_pred_schilla[:,2])\n",
    "print(f\"Percentuale di errori tra 0.45 e 0.5: {np.mean((errors > 0.45) & (errors <= 0.5)) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C-FREE\n",
    "points_free, labels_free, train_ds_free, val_ds_free, test_ds_free, NUM_POINTS, NUM_FEATURES = load_and_preprocess_naca_data('data/points_zenodo.npy','data/labels_zenodo.npy', \n",
    "                                                                                                                              BATCH_SIZE, TRAIN_SIZE, TEST_SIZE, augment=False, augment_factor=3, scale= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Pt = PointTransformerModel(NUM_POINTS, NUM_FEATURES, NUM_TARGETS, invariant = False)\n",
    "\n",
    "history_Pt = Pt.train(train_ds_free, val_ds_free, epochs=1000, patience=10)\n",
    "\n",
    "\n",
    "Pt.evaluate(test_ds_free)\n",
    "\n",
    "Pt.plot_training_history(history_Pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_cross_validation_PT(points_free, labels_free, NUM_POINTS,\n",
    "                            NUM_FEATURES, NUM_TARGETS, n_splits=5, batch_size=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bsblst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
